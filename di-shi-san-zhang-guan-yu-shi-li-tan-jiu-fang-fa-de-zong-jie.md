# 第十三章 关于实例探究方法的总结

## 13.1 引言

在本书的第II部分中，我们主要探究、分析了一系列的解释方法，试图分析模型在对实例层面上的预测情况。其中一章节主要讨论某一种方法。在实践中，单独使用这些方法的情景很少，反而如果将这些不同的模型所产生的分析结果结合起来往往有助于提供一个更加全面的分析。

图13.1是对这些方法的图形化的展示。这些图形展示了对基于Titanic数据（章节4.1）所构建的随机森林模型（章节4.2.2）的4种不同的实例级别的解释方法。我们所研究的实例是Johnny\_D，一个在Southampton登船的8岁男孩。他是头等舱乘客，没有父母和兄弟姐妹陪同，票价是72英镑（章节4.2.5）。我们的目的是预测Johnny\_D的生还的概率。

在图13.1中，第一行展示了有关变量-贡献（Variable-attribution）和变量-重要性（Variable-importance）方法的很多应用。这些方法包括Break-Down\(BD\) 图像（第6章），Shapley Values（第8章），和 Local Interpretable Model-agnostic Explanations\(LIME\)（第9章\)。所有的结果一致表明那些最重要的解释性变量，从对Johnny\_D的生还可能性的预测概率来看，是age，gender，class，和fare。值得注意的是，那些由additive decompositions 产生的图像有可能不会完全正确，因为fare和class变量有可能会相互关联，age和gender变量之间可能会由交互。

在图13.1中，第二行展示了影响Johnny\_D生还概率的4个最重要的可解释性变量的Ceteris-Paribus\(CP\) profiles\(第10章\)。这些Profiles表明，增加年龄或将旅行舱位改为二等舱或者为”餐馆员工“会降低对生还可能性的预测概率。另一方面，降低票价，将性别改变为女，或者将旅行舱改为”deck crew“会增加生还的概率。

在图13.1中，第三行总结了4个可解释变量的单变量分布情况。我们发现，票价为72英镑，是Johnny\_D的票价，这是非常高的价格，而且很少有孩子在Titanic上。

图13.1很好的展示了不同的方法相互补充的观点，当结合在一起的时候，能够对关于模型对实例的预测结果来源提供更加深刻的见解.

![&#x56FE; 13.1 &#x5173;&#x4E8E;Random Forest model&#x5BF9;Titanic&#x7684;&#x4E00;&#x4E2A;&#x4E58;&#x5BA2;Johnny\_D&#x9884;&#x6D4B;&#x7ED3;&#x679C;&#x7684;&#x5B9E;&#x4F8B;&#x5C42;&#x9762;&#x7684;&#x89E3;&#x91CA;](.gitbook/assets/13-1%20%281%29.jpg)

尽管将这些不同的实例层面的解释方法结合起来能为我们提供更多有用的信息，但是值得我们注意的是，这些方法是具有很大的不同的，而且它们的适用性是依赖于所要处理的具体的问题的。这就是我们在本章中接下来要讨论的内容。

## 13.2  模型中可解释变量数

模型中可解释变量的个数是选择可解释方法的一个重要的标准。

### 13.2.1 Low to medium number of explanatory variables（较少数目的解释性变量）

一个具有较少变量的模型通常表示模型中特定的变量具有很好的解释性。一个具体的实例是在4.2.1节和4.2.3 节关于Titanic数据集所建立的模型的各个变量。

在这个例子中，CP profiles揭示了每个变量对模型的预测结果影响的详细信息。特别的，那些对模型的预测结果具有很大影响的变量能够通过用CP-Profile Oscillations（第11章）方法所筛选，然后通过用Individual-variable CP-profiles （第10章）进行图形化的展示。

### 13.2.2 Medium to a large number of explanatory variables\(较多数目的解释型变量\)

在具有较多数量可解释型变量的模型中，大部分（全部）的变量仍然具有可解释性。一个相关的例子是car-insurance 价格模型，在这个模型中，我们通过100+个包括司机和车的特征的行为数据来对保险的价格进行预测。

当解释性变量的数目增多时，用CP profiles来展示每个变量是会变得更加困难。在这种情况下，最常用的方法是第6章中所涉及的BD plots，或者是第8章中所讨论的Shapley values的plots。这些方法能够快速检测变量对模型的预测是具有正面还是负面的影响；它们甚至还能为我们提供这些变量对模型影响的大小。在必要时，这些方法还能够只针对那些具有极大影响的变量进行分析。

### 13.2.3 Very large number of explanatory variables \(特多数目的解释型变量\)

当模型所涉及的解释性变量数目特别多时，对每个单个变量的作用都进行解释是非常困难的。相关的例子是那些处理图像和文本的模型。对于图像处理的模型，每个可解释的变量可能相对应于图像中的一个像素点；对于文本处理的模型，每个变量可能相对应于一个文本中的每一个字符。因此，它们单个的可解释性的能力是非常有限的。而且，由于额外的计算开销，用基于CP Profiles，BD Plots, 和 Shapley Values等方法对模型的预测结果进行分析是不太可行的。反而，在第9章中所介绍的LIME，是解决这类问题的常用方法，因为它能够分析上下文相关的变量组。

## 13.3 Correlated Explanatory Variables\(关联的可解释性变量\)

当我们在分析本书中第II部分中所提出方法的特性时，我们通常用的假设是各个可解释性的变量相互之间是独立的。很显然，实际情况常常并不是这样的。例如，在apartment prices相关的数据集上（章节4.4.1），房间的数目和apartment的面积通常是正相关的，在Titanic数据集上，我们也可以在travel class 和ticket fare 变量上得到相似的结论（章节4.1.1）。

当然的，从技术层面上来讲，即便当各个可解释性变量相互之间是相关的情况下，我们仍然可以用所有提到的相关的方法对数据进行分析。然而，在这种情况下，分析的结果可能是具有误导性的甚至是不切合实际的。

要想解决相关的这类问题，我们可以考虑构造新的独立的变量。这种方法有时某些情况下是可行的，如利用相关的应用领域知识或者利用适当的统计分析的方法，如，主成分分析法。另一种方法是构建2-d CP Plots（如章节10.5）或者是进行变量的块变换来保证当计算Shapley value（第8章）或BD Plots（第6章）时各个变量之间的结构相关性。

## 13.4 Models with interactions\(具有交互性的模型\)

在具有交互性的模型中，一个可解释变量的影响可能会受到其他可解释性变量的影响。例如，在Titanic中的乘客的生还率可能会随着年龄的增长而下降，但是这种影响将会随着不同的travel-class而不同。

在这种情况下，为了研究和解释一个模型的预测结果，我们不仅要考虑单个的变量，而且要考虑各个变量之间的交互性。为了确定交互性，我们可以应用第7章中所介绍的iBD Plots方法。为了解释交互结果，我们可以利用CP Profiles来展示。特别的，对于Titanic的例子，对于那些仅在gender上不同的实例，我们可以利用CP Profiles来分析age的影响。对于这些Profiles，越不平行，则相应变量的交互的影响就越强。

## 13.5 Sparse explanations\(稀疏解释\)

对于一个实例，预测性模型可能会利用成百的可解释性变量来生成预测。然而，对于有意义的解释性和说明性，大部分人只能够处理有限数目（比如，10个以下）的变量。因此，稀疏解释就成为研究的重点。对于构造这种情况下的解释性，最常用的方法是LIME（第9章）。然而，对于一个复杂的模型，构造一个稀疏的解释不是一件容易的事而且可能会具有很大的误导性。因此，当我们在非常复杂的模型上利用LIME时，我们需要格外小心。

## 13.6 Additional uses of model exploration and explanation\(对模型的研究和解释的其他用法\)

在本书第II部分的前一些章节中，我能主要侧重于所提出的各个方法对于预测模型的探究和解释方面的应用。然而，这些方法还可以有其他各个方面的应用：

* Model Improvement/debugging：如果模型对某一个实例的预测表现非常差，那么研究导致模型在这个特定样本上表现差的原因，能提供一些提高模型性能的线索。在基于实例的预测中，检测一个选定的解释变量相对于观测到的变量的不同影响是很容易的。
* Additional domain-specific validation：理解哪个因素会影响模型的预测结果能够帮助我们评估模型的有效性。如果模型中一些可解释变量的影响与我们的领域知识不想一致，这会给我们提供一些审视模型的基础，甚至转换模型。另一方面，如果一些变量对模型预测结果的影响与我们先前的期望是一致的，用户将会对模型更加信赖。这种信赖是将模型用于一些非常严肃的场景（如，医学中的预测模型）中进行支持决策的基础。
* Model selection：在有多个候选模型的场景中，我们可以根据模型解释的结果来筛选模型。这种情况很常见，即便是两个模型在整体的表现上具有很大的相似性，其中的一个模型会很有可能在局部上比另一个模型表现更好。例如，下文这个模型，一个具有很大程度上假设性的例子。假设一个模型用来预测某一区域，某一天是否会下雨，在基于有一半的时间是下雨的数据集上。考虑了两个不同的模型：一个是预测每隔一天会下一次雨；另一个是预测从10月到3月每天都会下雨。显然，两个模型都（至少认为）很简单，但是它们平均预测结果是有一半的时间将会下雨（我们可以认为，这两个模型都被较好的校准了，如章节15.2）。然而，对基于实例的预测（如每一天的下雨概率）会导致更加倾向于它们其中的一个模型。
* New Knowledge Extraction：机器学习的模型主要是为了提高预测的有效性。就像Leo Breiman\(2001b\)所提到的那样，相较于基于对某一现象的理解所建立的模型而产生感兴趣的值，（机器学习）是另外一种形式。而且，模型的解释有时有助于在特定的领域里提取新的，有用的知识，尤其是在那些我们没有足够领域知识的领域内。

## 13.7 Comparison of models \(Champion-Challenger analysis\) \(模型之间的比较\)

这些分析和解释模型的方法有很多不同的应用，其中的一个就是提供了对比不同模型的机会。

有很多情况，我们会对“冠军-挑战”感兴趣。假设，一些机构采用一种预测模型，但是想知道如果利用其它的模型是否会得到更好的结果。例如，银行中的风险投资部门可能会利用Logistic regression 来评估信用风险。这种模型可能会表现得很完美，因此，可以称之为“冠军”，如“在Logistic regression 类中表现最好的模型”。然而，部门想要检测一个“挑战者”，例如，一个更加复杂的模型，如 boosting 或 random trees ，是否会表现不好。如果这个“挑战者”有更好的表现，一个问题就是：这个挑战者模型如何不同于冠军模型？

另一个我们想比较模型的原因是，建模过程本身是一个迭代的过程（章节2.2）。在这个过程中，有很多不同的模型将会被构建，它们经常具有不同的结构，但是有时会有很相似的表现。比较分析能够更好的为我们提供两个模型是如何不同的。

如下我们提供了一个关于Logistic regression的对比分析的例子titanic\_lmr（如章节4.2.1），random forest模型titanic\_rf（如章节4.2.2）,boosting 模型 titanic\_gbm（如章节4.2.3）以及Support-Vector Machine（svm）模型 titanic\_svm（如章节4.2.4）。我们将Johnny\_D（如章节4.2.5）作为一个感兴趣的实例。

值得注意的是模型并不是完全不同。Random Forest模型和Boosting 模型是基于树状结构的模型，它们具有一个越界响应（预测）曲线。它们的复杂度是由于所涉及较大数目的树，当进行预测时。Logistic regression和SVM模型会产生连续，平滑的响应曲线。它们的复杂性来源于logistic regression模型包含样条变换，而SVM 模型是利用非线性的核函数。这些方法的不同导致了在预测Johnny\_D生还概率的不同结果。特别的，对于Random Forest，Logistic Regression，Gradient Boosting和SVM 模型的响应的预测生还概率为：0.42，0.77，0.66，和0.22。



## 



