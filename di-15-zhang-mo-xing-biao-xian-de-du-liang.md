# 第15章 模型性能的度量

## 15.1 引言

在本章，我们介绍了对（预测）模型整体性能评估的度量方法。

如第2.1节和2.5所提到的（那样），通常，我们可以从统计模型方面来区分解释型和预测型方法。Leo Breiman \(2001b\)指出，对模型（性能）的评估可以从两个方面进行：评估_goodness-of-fit_ \(GoF\)和用_Goodness-of-prediction_ \(GoF\)来评估预测准确率。主要的，GoF通常是用于可解释性的模型中，而GoP则通常是用于预测型模型中的。概括来说，GoF用于研究：构建模型所用的变量预测目标变量的贴合程度是多少？而GoP 用于研究：所构建的模型对于一个新的实例的预测性能如何? 对于一些评估方法，对于GoF和GoP 的解释，通常是基于这些评估方法是基于训练集计算得出的还是基于测试集得出的。

这些模型的评估方法可以用在以下几个方面：

* Model Evaluation: 如果我们想知道模型的表现，例如，模型的预测值的可靠性（我们所期望的error的频率和大小是多少？）？
* Model Comparison: 我们可能会想要对比两个模型的性能，基于此来选择其中一个；
* Out-of-sample and out-of-time comparisons: 我们想评估当模型被用于新的数据上的时候的表现是否会变差；

根据dependent variable的类型（e.g., continuous, binary, categorical, count, etc），我们可以使用不同的性能的评估方法。而且，当新的应用产生时，评估方法也在不同的也在增加。在本章中，我们仅讨论特定的一些评估方法，其中的一些方法将会在接下来的几章中陆续介绍。同时，针对dependent variables我们也只考虑连续性（包括count）和类别型（包括binary）的两种情况。

## 15.2 Intuition

大多数模型性能的评估，是基于模型对dependent variable 的预测值与数据集中（已知）的实际值不同的。在理想的情况是，模型对样本的预测值和实际值应该是相等的。而在实际情况中，这两者之间通常是由差异的，我们通常要量化他们之间的不同。

原则上，我们能够在训练数据集（如，那些用来训练模型的数据）上计算模型的性能。但是，这种计算方式会有过度预测模型表现性能的严重风险。一个有用的方法是利用一个独立的测试集来测试模型的性能。另外，当我们在训练集上计算模型性能时，可以使用一种偏置校正策略。基于这个目的，我们提出了很多种不同的评估策略，如交叉-验证或者bootstrapping（Kuhn and Johnson,2013; Harrell 2015; Steyerberg 2019）。接下来，我们主要研究数据分割的策略，例如，我们假设可以将现有的数据集分割成训练集和测试集。模型通常是建立在前一个数据集上，而后一个数据集通常是用来评估模型的性能。

值得注意的是，预测有两个重要的方面：calibration和discrimination（Harrell, Lee, and Mark, 1996）。Calibration通常是指预测值的bias的程度，例如，预测值和实际值的差异的平均值。Discrimination是指模型区分预测值与实际值的能力。例如，对于一个用来预测某个区域天气情况的模型，通常情况下，这个区域有半年是下雨的。一个简单的模型如果预测每隔一天就会下雨，那么这个模型是well-calibrated。因为，平均情况下，在一年中所预测的每天下雨的概率是50%，这与实际情况相符。然而，这个模型的discrimination的能力并不是很好（对于每天，所预测的下雨的概率是50%，这个与随机投硬币的概率是一样的），在这种情况下，这个模型的用处不大。

而且，除了整体的评估方法GoP以外，我们可能需要针对calibration和discrimination的额外的评估方法。值得注意的是，在以后的研究中，我们通常要区别这两个不同的情境：一个是预测值大于实际值的情况和预测值小于实际值的情况。对于如何来weigh不同类型的disagreement，我们可能需要不同的评估方法。

在最好的情况下，我们可以事先指定一个评估模型性能的方法，然后再建立和优化该模型。但是，在实际情况下，我们通常使用多种不同的模型性能的评估方法，而这些方法通常是在模型建立后而选择的。

## 15.3 Method

假设我们有一个关于 $$p$$ 个解释型变量，一个因变量 $$Y$$ 的 $$n $$个样本的训练数据集。其中，$$\underline{x}_i$$ 表示第 $$i$$ 个样本的解释变量的值的（列）向量， $$y_i$$ 表示相应的因变量的值。我们用 $$\underline{X}=(x_1',...,x_n')$$ 表示 所有这$$n $$ 个样本的解释变量的矩阵， $$\underline{y}=(y_1,...,y_n)'$$ 表示因变量的值的（列）向量。

训练集是用来构建模型  $$f(\underline{\hat{\theta}};\underline{X})$$ ，其中 $$\underline{\hat{\theta}}$$ 是对模型回归系数的估计，而且在这里，我们也可以使用“惩罚”估计参数 $$\underline{\tilde{\theta}}$$ \(详见，章节2.5\)。同时， $$\hat{y}_i$$ 为模型针对 $$y_i$$的估计值。 

对模型性能的分析通常是基于一个独立的数据及，这个数据集叫测试集。在有的情况下，采用Leave-One-Out方法对模型性能进行度量。此时，我们用 $$\underline{X}_{-i}$$ 表示在原数据集中除去第 $$i$$个样本后，剩余样本的解释变量所组成的矩阵， $$f(\underline{\hat{\theta}}_{-i};\underline{\hat{X}}_{-i})$$表示在除去第 $$i$$ 个样本后的剩余样本上所构建的模型。值得注意的是基于 $$Leave-One-Out$$ 方法所构建的模型 $$f(\underline{\hat{\theta}}_{-i};\underline{\hat{X}}_{-i})$$ 与基于所有样本所构建的模型 $$f(\underline{\hat{\theta}};\underline{X})$$ 是不同的。但是在大多数的情况下，它们所得到的结果是相接近的，而且在一个模型上所得出的结论通常能够转换到另一个模型上。此外，我们用 $$\hat{y_i}_{-i}$$ 表示基于模型 $$f(\underline{\hat{\theta}}_{-i};\underline{\hat{X}}_{-i})$$ 对 $$y_i$$ 的预测值。

在接下来的章节中，我们将会展示不同的模型性能的度量方法。通常，这些度量方法在本质上对于训练集和测试集上是一样的。如果在对这两种情况的解释上或是属性上有任何不同，我们将会明确的指出。另外需要注意的是，在下文中，我们将会在符号表示中忽略我们考虑了估计模型 $$f(\underline{\hat{\theta}};\underline{X})$$，我们将会用 $$f()$$作为其通用的表示符号。

###  15.3.1 连续的因变量

#### 15.3.1.1 拟合优度

对于连续的因变量的模型的拟合优度（GoF）的度量最常用的方法是平均平方误差，有如下定义： 

$$MSE(f,\underline{X},\underline{y})=\frac{1}{n}\sum_{i=1}^{n}(\hat{y}_i-y_i)^2=\frac{1}{n}\sum_{i}^{n}r_i^2,   $$      \(15.1\)

其中， $$r_i^2$$ 表示在第 $$i$$ 个样本上的残差（详见章节2.3）,因此， $$MSE$$ 可以看成对所有残差的平方的和。而且 $$MSE$$ 是一个凸可微的函数，这个从优化的角度来看是非常重要的（详见章节2.5）。由于这种度量方法对为所有的残差分配相同的权重，而残差比较大的样本能够对 $$MSE$$ 产生比较大的影响。因此，这种方法对“野值”非常敏感。对于一个“完美”的模型，他将会正确的预测所有的实际值 $$y_i$$，其 $$MSE=0$$。 

值得注意的是，基于$$MSE$$ 的度量方法是构建在具有不同尺度的因变量上的，因此，一个基于该模型的、更加可解释的度量模型是均方根误差（ $$RSME$$ ）模型，有如下定义： 

$$RMSE(f,\underline{X},\underline{y})=\sqrt{MSE(f,\underline{X},\underline{y})}$$        \(15.2\)

一个对于 $$RMSE$$ 应用比较广泛的变体是它的规范化的形式， $$R^2$$ ,有如下定义：

$$R^2(f,\underline{X},\underline{y})=1-\frac{MSE(f,\underline{X},\underline{y})}{MSE(f_0,\underline{X},\underline{y})}$$        \(15.3\)

在公式 15.3中， $$f_0$$ 表示“基准模型”。例如，对传统的线性回归模型， $$f_0 $$ 是只包括截距的模型，这个模型表示，该模型是利用所有样本的因变量 $$Y$$ 的均值作为对所有样本值的预测。 $$R^2 $$ 是规范化的度量，是在如果模型是“完美”模型的情况下 $$R^2=1$$ ,而 $$R^2=0$$ 表示该模型的表现并不优于我们的基准模型。在传统的线性回归的情况下， $$R^2$$ 是我们所熟知的判定函数的回归系数，可以被解释为：模型 $$f $$ 所能够解释的对于 $$Y$$的总体方差的比例。 

由于 $$MSE$$ 对“野值”非常敏感，因此有时我们也考虑使用绝对偏差的中值（median absolute-deviation, MAD）:

$$MAD(f,\underline{X},\underline{y})=median(|r_1|,...,|r_n|)$$     \(15.4\)

相比于 $$MSE$$ , $$MAD$$ 方法对于“野值”更具有鲁棒性。而 $$MAD$$ 的一个缺点是比较难解释的数学特性。

在15.4.1节中，我们将会阐述对于线性回归模型和随机森林模型的评估方法在公寓-价格数据集上的用法。





